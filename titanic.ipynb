{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQq7GdMUwZ1bmx7HbPBu6l"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNEIOET_iD6W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://media.githubusercontent.com/media/rahgirrafi/kaggle/master/titanic/train.csv'\n",
        "df = pd.read_csv(url)\n",
        "#df.describe()\n",
        "#df.head()\n"
      ],
      "metadata": {
        "id": "SuvqIoB2pCHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "VZVOCaQ4Ar7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:,['Pclass', 'Cabin', 'Survived']].head(50)"
      ],
      "metadata": {
        "id": "ID4UYAk2AqWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:,['Pclass', 'Cabin','Survived']].tail(50)"
      ],
      "metadata": {
        "id": "WMU9XELd_3qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['Sex'] = df['Sex'].replace('male',0)\n",
        "#df['Sex'] = df['Sex'].replace('female',1)\n",
        "#df['Embarked'] = df['Embarked'] .replace('C',0)\n",
        "#df['Embarked']  = df['Embarked'].replace('Q',1)\n",
        "#df['Embarked']  = df['Embarked'].replace('S',2)\n",
        "df['Embarked']  = df['Embarked'].replace(np.nan,'N')\n",
        "df['Cabin']  = df['Embarked'].replace(np.nan,'N')\n",
        "\n",
        "#df['Embarked'].unique()\n",
        "df.shape\n",
        "df.info()"
      ],
      "metadata": {
        "id": "5TVHkTm1W9gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['farePerPerson'] = df['Fare']/(df['Parch']+df['SibSp']+1)\n",
        "df['cllasFareRatio'] = df['Fare']/df['Pclass']\n",
        "\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "KTY298LY1I3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = StratifiedShuffleSplit(n_splits = 1, test_size = .2, random_state= 0)\n",
        "\n",
        "for train_idx, test_idx in splitter.split(df, df[['Sex','Pclass','Survived']]):\n",
        "  train = df.loc[train_idx]\n",
        "  test = df.loc[test_idx]\n"
      ],
      "metadata": {
        "id": "I2qNTLdExQgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "survived_by_gender = df.groupby('Sex')['Survived'].sum()\n",
        "print(survived_by_gender)\n",
        "gender_labels = survived_by_gender.index\n",
        "survivor_counts = survived_by_gender.values\n",
        "\n",
        "plt.bar(gender_labels, survivor_counts, color=['blue', 'pink'])\n",
        "plt.xlabel('Sex')\n",
        "plt.ylabel('Count of Survivors')\n",
        "plt.title('Survivors on the Titanic by Gender')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TPw3i0N_s_B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.corr(), annot= True)"
      ],
      "metadata": {
        "id": "5qB29ePXKOdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = df.columns[:]\n",
        "for i in cols:\n",
        "  sns.countplot(x= df[i], hue=df['Survived'])\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "-CU3v1AM5Hhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class featureEncoder(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    encoder = OneHotEncoder(sparse= False)\n",
        "    mat = encoder.fit_transform(X[['Embarked']]) #fit_transform expects a 2D array\n",
        "    columns=['C', 'Q', 'S']\n",
        "\n",
        "    for i in range(len(columns)):\n",
        "      X[columns[i]]=mat.T[i]\n",
        "\n",
        "    mat = encoder.fit_transform(X[['Sex']])\n",
        "    columns = ['female', 'male']\n",
        "\n",
        "    for i in range(len(columns)):\n",
        "\n",
        "      X[columns[i]]= mat.T[i]\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "Xg3G-dAAp9jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping unnecessary columns\n",
        "class featureDropper(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    toDrop = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Sex', 'Embarked']\n",
        "    X= X.drop(columns=toDrop)\n",
        "\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "eeTOyg2HiQ9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#handling missing values\n",
        "class featureImputer(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    ageImputer = SimpleImputer(strategy = 'mean')\n",
        "    X['Age'] = ageImputer.fit_transform(X[['Age']])\n",
        "    embarkedImputer = SimpleImputer(strategy = 'most_frequent')\n",
        "    X['Age'] =  X['Age'].floordiv(10)\n",
        "    X['Embarked'] = embarkedImputer.fit_transform(X[['Embarked']])\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "HWBu7PYglkKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('imputer', featureImputer() ),\n",
        "    ('encoder', featureEncoder() ),\n",
        "    ('dropper', featureDropper() )\n",
        "])\n",
        "preprocessed_train = pipeline.fit_transform(train)\n",
        "preprocessed_test = pipeline.fit_transform(test)\n",
        "preprocessed_Df = pipeline.fit_transform(df)\n"
      ],
      "metadata": {
        "id": "ndtA62IyscGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_Df.head(50)"
      ],
      "metadata": {
        "id": "drCO2P7AM0Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling/ normalization of Training set\n",
        "X_train = preprocessed_train.drop(columns=['Survived'])\n",
        "y_train = preprocessed_train['Survived']\n",
        "y_train = y_train.to_numpy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "3URwCfn4neOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling/ normalization of Testset\n",
        "X_test = preprocessed_test.drop(columns=['Survived'])\n",
        "y_test = preprocessed_test['Survived']\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "y_test = y_test.to_numpy()\n"
      ],
      "metadata": {
        "id": "iTemuYAsbc8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling/ normalization of Full Dataset\n",
        "X_final = preprocessed_Df.drop(columns=['Survived'])\n",
        "y_final = preprocessed_Df['Survived']\n",
        "X_final = scaler.fit_transform(X_final)\n",
        "y_final = y_final.to_numpy()\n",
        "X_final"
      ],
      "metadata": {
        "id": "B5aDVRBqkzAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model selection\n",
        "\n",
        "tree = RandomForestClassifier()\n",
        "param_grid = {\n",
        "    'n_estimators': [100,500,1000],\n",
        "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "    'max_depth': [None,5,10,20],\n",
        "    'min_samples_split':[2,3,4],\n",
        "\n",
        "}\n",
        "\n",
        "gridSearch = GridSearchCV(tree, param_grid, cv = 5, scoring = 'accuracy', n_jobs= -1, return_train_score = True)\n",
        "\n",
        "gridSearch.fit(X_train, y_train)\n",
        "#tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "bY13DjVpu-Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_tree = gridSearch.best_estimator_\n",
        "chosen_tree\n",
        "tree = RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_split=6, n_estimators=800)\n",
        "tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "35GrDXVuNTBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "ezIMuEXobPdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final model selesction\n",
        "final_tree = RandomForestClassifier()\n",
        "param_grid = {\n",
        "    'n_estimators': [100,500,1000],\n",
        "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "    'max_depth': [None,5,10,20],\n",
        "    'min_samples_split':[2,3,4],\n",
        "\n",
        "}\n",
        "\n",
        "gridSearch = GridSearchCV(final_tree, param_grid, cv = 5, scoring = 'accuracy', n_jobs= -1, return_train_score = True)\n",
        "\n",
        "gridSearch.fit(X_train, y_train)\n",
        "final_chosen_tree = gridSearch.best_estimator_"
      ],
      "metadata": {
        "id": "k7t41oNzPRjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_tree = RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_split=6, n_estimators=800)\n",
        "final_tree.fit(X_final, y_final)"
      ],
      "metadata": {
        "id": "58kC7mgdla5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_url = 'https://media.githubusercontent.com/media/rahgirrafi/kaggle/master/titanic/test.csv'\n",
        "X_test_Data_ = pd.read_csv(test_url)\n",
        "X_test_Data_['farePerPerson'] = X_test_Data_['Fare']/(X_test_Data_['Parch']+X_test_Data_['SibSp']+1)\n",
        "X_test_Data_['cllasFareRatio'] = X_test_Data_['Fare']/X_test_Data_['Pclass']\n",
        "\n",
        "X_test_Data = pipeline.fit_transform(X_test_Data_)\n",
        "X_test_Data['Fare']  = X_test_Data['Fare'].replace(np.nan, X_test_Data['Fare'].mean())\n",
        "X_test_Data['farePerPerson']  = X_test_Data['farePerPerson'].replace(np.nan, X_test_Data['farePerPerson'].mean())\n",
        "X_test_Data['cllasFareRatio']  = X_test_Data['cllasFareRatio'].replace(np.nan, X_test_Data['cllasFareRatio'].mean())\n",
        "\n"
      ],
      "metadata": {
        "id": "XkzMRGlqm5tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_Data.describe()"
      ],
      "metadata": {
        "id": "Kf4VS0k1S9qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "D9UpSY0CUi9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_final = scaler.fit_transform(X_test_Data)\n"
      ],
      "metadata": {
        "id": "GKE90sLpo0OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preidctions = final_tree.predict(X_test_final)\n",
        "\n",
        "final_df = pd.DataFrame(X_test_Data_['PassengerId'])\n",
        "final_df['Survived']= preidctions\n",
        "final_df.to_csv('predictions.csv',index= False)"
      ],
      "metadata": {
        "id": "2tj_UY3lpNIR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}